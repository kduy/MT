%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{FlinkCQL- Queries over Data Stream}

\ifpdf
    \graphicspath{{Chapter4/Figs/Raster/}{Chapter4/Figs/PDF/}{Chapter4/Figs/}}
\else
    \graphicspath{{Chapter4/Figs/Vector/}{Chapter4/Figs/}}
\fi


\subsection*{Query}

A query is a request telling system what to do in order to retrieve or alter desired information stored or processed by system. For instances, asking ``How many products are sold today? ''. Queries over data stream and in a traditional DBMS have a lot in common; however, due to characteristic of continuousness in data stream, we may classify a query as one-time query or continuous query \citep{Terry:1992} \citep{Babcock:2002}. 
\begin{itemize}
	\item \textbf{One-time queries} are evaluated once over data set at a given time instant, and terminated after returning its result. This is also called \textit{passive query} \citep{SmartVotex:2011} since system require queries and passively waits for users to issue these queries before executing. 
	\item \textbf{Continuous queries}, in contrast, get evaluated continually as new data arrives to the observed stream. System continuously delivery new results  over time according to the snapshot or state of data stream seen so far. Thus the output of queries is not a single result, but rather new streams of results for further operators if desired. Obviously, continuous queries really fit to user's requirements to observed data streams till its end. 
\end{itemize}



\subsection*{Query Language}
Queries are expressed in terms of some query language. Queries provide for users and programmers a very general way to specify data selections, projections, combination, computation and so on over data set/stream. In the meanwhile, users can send the queries using either imperative or declarative language.

\subsubsection*{Imperative vs. Declarative language}
\begin{itemize}
	\item \textbf{Imperative language} requires users to define explicitly step by step \textbf{how} code should be executed to get \textbf{what} they want. They need to break the program into sequences of commands in particular order for the system to perform. Actually, many existing programming languages are imperative supporting \textit{assignemnt}, \textit{for-loop}, \textit{if-else} statements and so on to construct the complete program. For example, assuming that \textit{StockTick} is a  list of stock transactions,  to filter through \textit{StockTick} to get all stock transactions from `NYSE' only: 
\begin{lstlisting}
	function getTransFromNYSE {
		var fromNYSE = []
		for (var i = 0; i < StockTick.length; i++) {
			if (StockTick[i].Exchange == "NYSE")
				fromNYSE.add(StockTick[i])
		}
	}
\end{lstlisting}
	\item \textbf{Declarative language}, like SQL or LINQ, users just specify \textbf{what} they want - which sort of data, which transformation they want it to be afterwards, but \textbf{not how} to achieve the result. The corresponding declarative program for previous examples is written in SQL language as below:
	\begin{verbatim}
		SELECT * from StockTick where Exchange = "NYSE"
	\end{verbatim}
\end{itemize}

There are several advantages of declarative over imperative language \citep{Martin:2014}:

\begin{itemize}
	\item Declarative language is typically more concise , more friendly and easier to work with. For instance, comparing 2 previous programs, the former has 7 lines of code while the latter goes with 1 line. According to \citep{Ronnie:2015}, Java program is typically 50 times less compact than SQL query for the same purpose. Generally, that because they have different level of abstraction. Declarative language already hides complicated implementation details. It makes the program much more simpler but possible for system to introduce underneath improvement without any impact on queries.
	\item Declarative languages, for example SQL, HTML,  are usually followed a set of standard syntaxs which make it more limited in functionality, give the system more room for automatic optimization. 
	\item In terms of parallel execution environment, declarative language like SQL has a better chance to be executed faster. Imperative code instructs its sequence of operators to be performed in a certain order so that it is really hard to parallelize programs across distributed system. In the other hand, declarative queries are more atomic to be implemented in parallel if appropriate.
\end{itemize}

\subsection*{FlinkCQL - a SQL-like dialect}
Recently, there are 2 common form of declarative language applying to data query: SQL and LINQ. However, we decide to extend SQL syntax for our continuous query language due to several advantages:
\begin{itemize}
	\item Traditional database model and data stream model are distinguished but till share many common features and operators. Since,SQL was a well-designed for handle data in batch mode, extending it to handle data-in-motion in data stream model is a possible incremental approach to quickly define language with less effort.
	\item SQL is so common and recognized by most of developers. Therefore, extended SQL languare would not challenge them to learn and master it.
	\item SQL is a standard adopted by most of relational database systems. As a result, their syntax is well-designed and refactored. Moreover, parsers, visualizers and composers for SQL are readily available to extend.
\end{itemize}

http://www.sqlstream.com/blog/2015/03/why-we-need-sql-for-real-time-streaming-analytics/

	
%\subsubsection*{LINQ}
%https://www.linqpad.net/WhyLINQBeatsSQL.aspx
%http://pankajtiwarii.blogspot.hu/2012/09/advantages-and-disadvantages-of-linq_3.html

%Despite its power, LINQ doesn't deprecate SQL. It takes more than 95 percents of the querying brunt, but you still sometimes need SQL for:

%Hand-tweaked queries (especially with optimization or locking hints)

%Queries that involve selecting into temporary tables, then querying those tables

%Predicated updates and bulk inserts

%\subsubsection*{Visual languages} \citep{Henrique:2014}


There are several properties of data stream which we take into account when extending SQL to FlinkCQL:

\begin{itemize}
	\item \textbf{Language closure}: it ensures that the output of any one query can be input to another
	\item \textbf{Windowing} FlinkCQL allow to define window specification and  implement related operators
	\item \textbf{Non-blocking operators} Naturally, blocking operation is not applicable to data stream
\end{itemize}

We are hereby going to present FlinkCQL syntax on \ref{language} and its semantic  on \ref{semantic}





In the streaming literature, query language model a stream as a representation for an infinite append-only relation. The append-only stream model effects the following limitations\citep{Ghanem:2008}
\begin{itemize}
\item It limits the applicability of the language since the append-only models cannot represent streams from the various domain( e.g., the update streams or streams that represent concatenation of the states of a fixed size relation).
\item The append-only stream model limits the types of queries that the language can express since only non-blocking queries can produce append-only streams as output
\item The semantics of query composition in the append-only stream model is complex and the meaning of the composed queries is difficult to understand.
\end{itemize}

Query \citep{Babcock:2002} 

Query : Smart Votex , page 2

Window Specification over Data Streams.pdf

[Stream] Evaluate CQL

Designing\_Data\_Intensive\_Applications.pdf



%\section{Fundamental Features}

%\begin{itemize}
%\item Stream-oriented Query Languages and Operators
%	\begin{itemize}
%		\item Language closure
%		\item Windowing
%		\item Correlation
%		\item Pattern Matching
%	\end{itemize}
	
%\item Fundamental of Stream Processing : page 110
%	\begin{itemize}
%		\item Compositional elements
%		\item Declarative operators
%		\item Expression language
%		\item Type System
%		\item Windowing
%		\item Standard operators and adapters
%		\item Modularity
%		\item Configuration
%		\item Extensiblity
%	\end{itemize}
%\end{itemize}


\section{Continuous Query Language} \label{language}

\subsection{Data Type}

FlinkCQL supports numbers of data types including numeric types (\textit{Byte}, \textit{Short}, \textit{Int}, \textit{Long}, \textit{Float}, \textit{Double}), \textit{Boolean}  type, string types (\textit{Char}, \textit{String}), deta type (\textit{Datetime}) with detailed descriptions in (Table~\ref{table:Data Type})


\begin{table}[h]
\caption{Data Type}
\centering
\label{table:Data Type}
\setlength\extrarowheight{5pt}
\begin{tabular}{||>{\centering\bfseries}m{1in} |>{\centering}m{3in}  |>{\centering\arraybackslash}m{2in}||}
\hline
%\rowcolor[HTML]{ECF4FF} 
%{\color[HTML]{ECF4FF} \textbf{Scala Type}} & {\color[HTML]{ECF4FF} \textbf{Flink Type}} & {\color[HTML]{ECF4FF} \textbf{Viewable as}} \\ \hline
\textbf{FlinkCQL Type} & \textbf{Description}  & \textbf{Convertable to} \\ \hline\hline
                    String  & A sequence of Chars                               &  \\ \hline
                    Boolean	& Either the literal true or the literal false			               &   \\ \hline
                   Char		& 16 bit unsigned Unicode character. Range from U+0000 to U+FFFF			 &  Byte, Short, Integer, Long, Double\\ \hline
					Byte		 & 8 bit signed value. Range from -128 to 127          	                   & Short, Integer, Long,Float, Double \\ \hline
					Short	& 16 bit signed value. Range -32768 to 32767			               & Integer, Long, Float, Double\\ \hline								
					Int		& 32 bit signed value. Range -2147483648 to 2147483647			 & Long, Float, Double\\ \hline
					Long		& 64 bit signed value. -9223372036854775808 to 9223372036854775807	 		                     & Float, Double \\ \hline								
					Float	& 32 bit IEEE 754 single-precision float			                    & Double \\ \hline
					Double	& 64 bit IEEE 754 double-precision float			                  &   \\ \hline							
	Datetime				&     'YYYY-MM-DD HH:MM:SS' format. The supported range is '1000-01-01 00:00:00' to '9999-12-31 23:59:59'               &        	\\ \hline           							           							           							           							           
\end{tabular}
\end{table}



\subsection{Data Definition Language (DDL)}
We utilize Extended Backus–Naur Form (EBNF) to make a formal descriptions of FlinkCQL. To understand the syntax, there are some EBNF notations to know
\begin{itemize}
	\item $\textbf{[...]}$ : Expression inside squared brackets is \textit{optional}
	\item $\textbf{\{...\}}$ : Expression, which is wrapped by curly braces, is omitted or repeated. 
	\item $\textbf{|}$ : alternation (or)
\end{itemize} 
Moreover, be aware that \textit{ident} stands for \textit{Identifier} which is recognized as name of schema, stream, data field and so on.
\newpage
\subsubsection{Create Schema}

%\setlength{\grammarparsep}{20pt plus 1pt minus 1pt} % increase separation between rules
\setlength{\grammarindent}{12em} % increase separation between LHS/RHS 

\begin{grammar}

<schema statement> ::= CREATE SCHEMA <schema ident> \\
(<named schema ident>|<anonymous schema>) \\
  { }[EXTENDS <parent schema ident>]

<anonymous schema> ::= `(' <typedField> \{`,' <typedField>\}`)'

<typedField> ::= <field ident> <data type>

\end{grammar}
	
Similar to CREATE TABLE statement in SQL, we are able to identify a schema of stream tuples. Each schema consist of name followed by list of data fields (the combination of field identifier and its data type). For example, we create schema for \textit{StockTick} stream:
\begin{verbatim}
CREATE SCHEMA StockTickSchema (symbol String, sourceTimestamp Long, 
price Double, quantity Int, exchange String)
\end{verbatim}

We extends the grammar so that a schema can be referenced or extended to another schema. For examples, in below examples, \textit{StockTickSchema2} is referencing to previous \textit{StockTickSchema} so that they own a similar set of attributes. Meanwhile, \textit{StockTickSchema3} extends from it to have one more attribute (\textit{"id"})
\begin{verbatim}
CREATE SCHEMA StockTickSchema2 StockTickSchema
CREATE SCHEMA StockTickSchema3 (id Int) EXTENDS StockTickSchema
\end{verbatim}

\subsubsection{Create Stream}
	
					
\begin{grammar}
<Stream statement> ::= CREATE STREAM <schema ident> \\		(<named schema ident>|<anonymous schema> ) \\
{ }[<source>]

<source> ::= (AS <derived source>) | ( SOURCE <raw source>)

<derived source> ::=  <stream ident>| <subSelect>

<raw source> ::= 
				HOST `('<host>, <port>`)'
					\alt FILE `('<file path>, <delimiter>`)'
\end{grammar}

A stream cannot be queried unless it is registered with a schema, simply because system require users to specify name of attributes for expression in most of cases. For this reason, we allow to entitle a stream to its schema using CREATE STREAM statement. Except for the reserved keywords, the statement consists of 3 parts. Stream name declaration is followed by schema definition and source of stream. Its schema can be recalled from a previously-defined named schema such as \textit{StockTickSchema}. 
\begin{verbatim}
CREATE STREAM StockTick StockTickSchema;
\end{verbatim}

One also has abilities to define new schema with a set of attribute name and type. In this case, the stream and its schema share the same name.
\begin{verbatim}
CREATE STREAM StockTick (symbol String, price Double, quantity Int)
\end{verbatim}

The last part is optional source of stream. Recall that we have two kind of stream representations: base stream and derived stream. \textit{<raw source>} clause indicates that this is a base stream obtained through a network connection (\textit{<host>, <post>}) or from a text file. For instance, \textit{StockTick} stream originates from host \textit{98.138.253.109} via port \textit{2000}

\begin{verbatim}
	CREATE STREAM StockTick StockTickSchema 
	SOURCE HOST ("98.138.253.109", 2000)
\end{verbatim}

Derived stream may come from another existing stream or output of a query and its operators. \textit{<derived source>} clause indicates these two possibilities. For example, we register a new stream \textit{StockPrice} which is derived from \textit{StockTick} but pay attention to stock symbol and its price only
\begin{lstlisting}
	CREATE STREAM StockPrice (symbol String, price Double) AS
	SELECT symbol, price 
	FROM StockTick
\end{lstlisting}


\subsection{Data Manipulation Language (DML)}

\subsubsection{Insert}

\begin{grammar}
<insert statement> ::= INSERT INTO <stream ident> [AS] 
							(<stream ident> | <subSelect>)
\end{grammar}
% <merge>

In CREATE STREAM statement, stream identifier and its schema definition are required but its source is optional. It means that registered stream could attached its source later when it is available. In this case, we take the advantage of INSERT statement which help us to complete stream registration procedure. However, we support INSERT statement for derived stream only. It naturally makes sense because a base stream is concrete and should be permanently registered from beginning.
Keep in mind that INSERT statement is a complementary to CREATE STREAM statement in case \textit{<source>} is missing. It will not work for a stream identifier which already refer to a real stream source.

\begin{verbatim}
	CREATE STREAM StockTick StockTickSchema;
	INSERT INTO StockTick AS stockStream;
\end{verbatim}


\subsubsection{Merge}
\begin{grammar}
<merge statement> ::= MERGE <stream ident> `,' <stream ident> {,<stream ident>}
\end{grammar}

\subsubsection{Split}
\begin{grammar}
<split statement> ::= ON <stream ident> \\
						<insert clause> \{, <insert clause>\}
						
<insert clause> ::= INSERT INTO <stream ident> \\SELECT <target entry list> WHERE <predicate>
\end{grammar}

\begin{verbatim}
	on OrderEvent
  insert into LargeOrders select orderId, customer where orderQty >= 100
insert into MediumOrders select orderId, customer where orderQty between 20 and 100
  insert into SmallOrders select orderId, customer where orderQty > 0
\end{verbatim}



\subsubsection{Select}
\begin{grammar}
<select statement> ::= SELECT <target entry> \{, <target entry>\}\\
	FROM <stream references> \\
	WHERE <predicate> \\
	GROUP BY <field ident> \{,<field ident>\} \\
	INTO <stream ident>
	
<stream references> ::= <stream refererence> [<join clause>]

<stream reference> ::= (<stream ident>| <subSelect>) [`['Window specification`]']

<join clause> ::= CROSS JOIN <stream reference>
				\alt [INNER] JOIN <stream reference>

<window specification> ::= 
								SIZE <spec> \\
								{ }[EVERY <spec>]\\
								{ }[PARTITIONED BY <field ident> \{,<field ident>\}]

<spec> ::= <int> ON <field ident>
			\alt <int> <time unit>
			\alt <int>
\end{grammar}




\subsection{Operators}
\begin{enumerate}

\item Scala-based Operators
	\begin{itemize}
        \item Arithmetic
        \item Logical
        \item Comparison / Relational
        \item Bitwise
	\end{itemize}
	
 \item List and Range Operators
 	\begin{itemize}
        \item In / Not in
        \item Between
        \item Null
 	\end{itemize}
 \item String Operators
 	\begin{itemize}
        \item Like
        \item Regex
 	\end{itemize}
 \item Function 
 	\begin{itemize}
        \item Aggregate Func
        \item Coversion Func
       	\item Data and Time Func
        \item String func
 	\end{itemize}

\end{enumerate}
Semantic and Implementation of Continuous Sliding window queries over data streams

[thesis] CQL over data stream [BNF] alias



\section{Continuous Query Semantics and Operators} \label{semantic}
Semantics of Data Streams and Operators

\href{http://en.wikipedia.org/wiki/Relational\_algebra}{http://en.wikipedia.org/wiki/Relational\_algebra}
\subsection*{Denotation Language}
\subsection*{Lamda Calculus}

\subsection{Abstract Syntax}


\subsection{Domain}

\subsection{Denotation Semantics}








\subsection{Standard Operator}
\begin{itemize}
	\item filter $\sigma$
	\item map $\mu$
	\item grouping $\gamma$  
	\item union $\bigcup$
\end{itemize}

\subsection{Window Operators}
\begin{itemize}
\item Time-based Window
\item Count-based Window
\item Partitioned Window
\end{itemize}



