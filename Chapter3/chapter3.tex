%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{The execution semantic of Stream Processing in Flink (10 pages)}

\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

\section{Heterogeneity}
Since the first commercial project of Complex Event Processing launched by Bell Labs in 1998 with its "Sunrise Project", we have seen the fast growing of many stream processing frameworks. However, there is a huge degree of heterogeneity across these frameworks in various forms\citep{Dindar:2013}

\begin{enumerate}

	\item Syntax: Although the ISO/IEC 9075 is published standard to defines the complete syntax and operations in SQL language as a whole, there is no standard language for stream processing. Different stream processing engines use different syntax to depict the same function. For example,every 5 seconds, a window captures all event last 10 seconds. 
	\begin{verbatim}
	CQL: 	[RANGE 10 seconds SLIDE 5 second ] 
	Flink: 	[SIZE 10 sec EVERY 5 sec]
	\end{verbatim}
	
	\item Capability heterogeneity:
	Those engines also provide different set of query types and operations based on which functions they are capable of. For examples, \textit{Streambase} support pattern matching on stream, whereas STREAM does not.
	
	\item Execution Model: Below the language level, hidden from application layers, each stream processing engine has its own underlying execution model. With the same data stream but different model produce different output which varies based on the differences on tuple ordering,  window construction, evaluation and so on. We are going to focus on the differences between several existing execution models below.
	
	
\end{enumerate}
 
We have learned that there are at least three different execution models:
\begin{itemize}
	\item \textbf{Time-driven} execution model, followed by CQL, Oracle CEP. In the model, each tuple have a timestamp. Timestamp induce the total order of tuples on stream, but not a strict order. Or more specifically, there is no ordering between tuples with identical timestamps. These tuples are consider as simulanenous tuples. It is problematic when we select a window of last 10 tuples but more than 10 simultaneous tuples arrived at a given time instant. In this case, there is no different between those tuples, the system will select only 10 out of all in a non-deterministic way.
	
	// Draw:
	
	\item \textbf{Tuple-driven} execution model, followed by StreamBase, Apache Flink. In this model, tuples may have an application timestamp attribute on its schema. Some of timestamp value might be identical but they are completely distinguished in stream. There exists a strict total order in stream based on their arrival order. There are several ways to represent tuple order in stream. StreamBase system assigns an incremental internal rank to tuples to arriving tuples. It ensures that the tuple with lower rank with be processed before tuples with higher rank. In Apache Flink, we implicitly use system timestamp   $t_{sys}$ at which system receives the tuple. Since system timestamp are strictly totally ordered, it is simply suitable for Flink execution model. Several other works propose to use tuple Id\citep{Dinda:2013} or a physical identifier\citep{Petit:2010} instead. 
	//Draw: 
	
	\item \textbf{Batch-driven} execution model, followed by Coral8, mentioned in SECRET\citep{Botan:2010} descriptive model
\end{itemize}. In this model, each tuple is assigned an batch-id. Every tuple which belong to a batch must have the same timestamp, but 2 separate tuple with the identical timestamp may belong to two different batches. As we can see, batch-driven model is in between of tuple-driven and time-driven model. Assuming that at a given application timestamp $\tau$, the system receives 5 tuples ${<v_1,\tau>,<v_2,\tau>,<v_3,\tau>,<v_4,\tau>,<v_5,\tau>}$. Time-driven model treats them as simultaneous tuples with no difference. Tuple-driven considers them as 5 concrete tuples in strict order. And batch-driven model may divide them into 2 batches ${<v_1,\tau>,<v_2,\tau>,<v_3,\tau>}$, ${<v_4,\tau>,<v_5,\tau>}$ depending on window specification.

Extend the examples from \citep{Dinda:2013} with Flink implementation

Example 1: differences in window constructions

Example 2: differences in window evaluations

Example 3: differences in processing granularity

Check another examples at \citep{Jain:2008}

Example 1: Window state change

tuple: each tuple arrival cause a system to react
time: the progress of tapp cause a system to react
batch:  where either a new batch arrival or the progress of tapp cause a system to react

\section{Policy-based Window Semantics}


Flink constructs windows based on parameters in specification. Currently Flink does not support Predicate Window so that two of most critical parameters are to notify when system should trigger new windows (indicating the lower bound of window) and when system must end the window (indicating the upper bound of window) and emit it to window stream. For that purpose, Flink implements a mechanism called \textit{"Policy-based windowing"}. It is a highly flexible way to specify stream descretization. It has two independent policies corresponding to open and close window: Trigger and Eviction Policy.
To demonstrate the concepts of two policies, let's consider the scenario with \textit{StockTick} stream: check every 10 minutes the total transaction volume of all transaction last 30 minutes. In other words, in every 10 minutes create a new window to cover all the transactions in last 30 minutes. The syntax in Fink:

\begin{verbatim}
StockTick.window(Time.of(30, MINUTES))
		 .every(Time.of(10, MINUTES)).sum(Quantity)
\end{verbatim}

\begin{enumerate}

\item Eviction Policy: define the length of a window. The length is passed in to \textit{window(...)} function. It could be the time interval, number of tuples and delta function with threshold (in case of delta window).
We formalize the concept of window due to its size

\begin{defi}
A time-based window $W_{t} = (l,u,\omega)$ over a stream $S$ is a finite subset of  $\mathbb{S}$ containing all data elements $s \in \mathbb{S}$ where $l , u, \omega \in \mathbb{T}$ and$l < s.t \leq u$. The length of window in time unit is $\omega = u-l$
\end{defi}
Notice that in a time-based window, $s.t$ can be tuple's application or system timestamp depending on query. There are maybe many simultaneous tuple with identical $t_{app}$. However, there is at least one arriving tuple at a given $t_{sys}$. The second point is that $W_t$ open at $t = l$, it does not include tuple at this time instant.

\begin{defi}
A count-based window $W_{c} = (l,u,n)$ over a stream $S$ is also a finite subset of  $\mathbb{S}$ containing all data elements $s \in \mathbb{S}$ where $l,u \in \mathbb{T}$, $\omega \in \mathbb{N}$ and $l \leq s.t_{sys} \leq u$. The length of window is the number of tuples in interval time $[l, u]$, i.e., $|n {s \in \mathbb{S}(t_{sys}): l < s.t_{sys} \leq u}|$
\end{defi}
The count-based window $W_{c}$ is independent from application timestamp $t_{app}$. It is related to system timstamp $t_{sys}$ which indicate tuple's order in stream. 


\item Trigger Policy: In general, it defines window slide or the distance between 2 consecutive windows. On above example , trigger policy states that from beginning, system must trigger a new window every 10 minutes. No other window would be triggered within this 10 minutes. 

Suppose that we have 2 consecutive windows $W^1 = (l_1, u_1, \_)$ and $W^2 = (l_2, u_2, \_)$  where $l_1 < l_2$. There is no window $W^1 = (l_3, u_3, \_)$ such that $l_1< l_3 < l_2$.
\begin{itemize}

\item If $W_1$ and $W_2$ are time-based windows, a slide $\beta = l_2 - l_1$.  
\item If $W_1$ and $W_2$ are count-based windows, a slide $e = |{s \in \mathbb{S}(t_{sys}): l_1 < s.t_{sys} \leq l_2}| $ 

\end{itemize}

\end{enumerate}

If the correlation between window size and slide size  conforms to the movement type of windows.
\begin{itemize}
\item Sliding window: $\omega > \beta$ or $n > e$
\item Tumbling window: $\omega = \beta$ or $n = e$
\item Jumping window: $\omega < \beta$ or $n < e$
\end{itemize}

However, Flink allow to mix between time-based trigger policy with count-based eviction policy and vice versa. For example,
calculate sum of quantities of last 100 transactions every 1 hour.
\begin{verbatim}
StockTick.window(Count.of(100))
		 .every(Time.of(1, HOURS)).sum(Quantity)
\end{verbatim}

\section{The execution semantic}






